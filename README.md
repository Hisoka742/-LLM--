# Ограничения памяти в LLM-системах

## Описание

Данный репозиторий посвящён анализу архитектурных, вычислительных и прикладных ограничений памяти в больших языковых моделях (Large Language Models, LLM).  
Материал охватывает как теоретические основы (архитектура трансформеров, self-attention), так и инженерные подходы, применяемые в современных LLM-системах.

Особое внимание уделено следующим аспектам:

- ограничению длины контекста;
- квадратичной сложности механизма самовнимания;
- требованиям к оперативной памяти при инференсе и обучении;
- отсутствию истинной долгосрочной памяти у LLM;
- использованию внешней памяти и Retrieval-Augmented Generation (RAG).

---

## Назначение репозитория

Цель данного репозитория — предоставить структурированное и формальное изложение проблемы ограничений памяти в LLM-системах, а также обзор современных методов смягчения этих ограничений.

Материал может быть использован:

- в учебных целях (курсы по NLP и машинному обучению);
- при проектировании LLM-приложений;
- в исследовательской работе, связанной с масштабированием трансформерных моделей.

---

## Основной файл (deep dive)

Для детального и формального разбора темы предназначен файл:

**`memory_limits_llm.tex`**

В этом LaTeX-документе последовательно рассматриваются:

1. Типы памяти в LLM-системах  
   - параметрическая память;  
   - контекстная память;  
   - внешняя память.

2. Ограничение длины контекста  
   - механизм self-attention;  
   - квадратичная сложность по длине последовательности;  
   - практические пределы длины контекста.

3. Потребление памяти  
   - веса модели;  
   - активации слоёв;  
   - KV-cache;  
   - градиенты и состояния оптимизатора при обучении.

4. Отсутствие долгосрочной памяти  
   - потеря контекста между запросами;  
   - невозможность обновления весов в ходе диалога;  
   - необходимость реализации памяти на уровне приложения.

5. Инженерные подходы  
   - сжатие контекста;  
   - оконное и разреженное внимание;  
   - Retrieval-Augmented Generation (RAG);  
   - длинноконтекстные архитектуры.

6. Последствия для практических систем  
   - работа с длинными документами;  
   - латентность и стоимость инференса;  
   - требования к инфраструктуре.

7. Будущие направления  
   - объединение внешней и внутренней памяти;  
   - модели с постоянной памятью;  
   - альтернативные attention-механизмы.

---

## Важно

README.md предназначен для краткого обзора и навигации по материалу.

Глубокий технический и теоретический разбор темы содержится исключительно в файле:

**`memory_limits_llm.tex`**

Для полного понимания архитектурных ограничений и инженерных компромиссов рекомендуется изучать именно этот документ.

---

## Связь с реальными моделями

Рассматриваемые в работе ограничения применимы к большинству современных LLM, включая:

- GPT-подобные модели;
- LLaMA и производные архитектуры;
- Claude и другие коммерческие модели;
- длинноконтекстные модификации трансформеров.

Независимо от реализации, фундаментальные ограничения self-attention и контекстного окна сохраняются и определяют практические пределы масштабирования.

---

## Сборка PDF из LaTeX

Для компиляции PDF-версии документа выполните:

```bash
pdflatex memory_limits_llm.tex

